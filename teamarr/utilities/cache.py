"""Cache implementations with TTL support.

Two cache backends available:
- TTLCache: In-memory, fast, resets on restart
- PersistentTTLCache: SQLite-backed, survives restarts

TTL recommendations:
- Team stats: 4 hours (changes infrequently)
- Team schedules: 8 hours (games added/removed rarely)
- Events/scoreboard: 30 min today, 8 hours past/future
"""

import json
import logging
import threading
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """A cached value with expiration."""

    value: Any
    expires_at: datetime
    last_accessed: datetime


class TTLCache:
    """Thread-safe in-memory cache with TTL and size limit.

    Features:
    - Time-based expiration (TTL)
    - Maximum size limit with LRU eviction
    - Thread-safe operations
    - Automatic cleanup of expired entries

    Usage:
        cache = TTLCache(default_ttl_seconds=3600, max_size=10000)
        cache.set("key", value)
        result = cache.get("key")  # Returns None if expired
    """

    # Default max size (0 = unlimited)
    DEFAULT_MAX_SIZE = 10000

    def __init__(
        self,
        default_ttl_seconds: int = 3600,
        max_size: int = DEFAULT_MAX_SIZE,
    ):
        self._cache: dict[str, CacheEntry] = {}
        self._default_ttl = timedelta(seconds=default_ttl_seconds)
        self._max_size = max_size
        self._lock = threading.Lock()
        self._hits = 0
        self._misses = 0

    def get(self, key: str) -> Any | None:
        """Get value if exists and not expired."""
        with self._lock:
            entry = self._cache.get(key)
            if entry is None:
                self._misses += 1
                return None
            if datetime.now() > entry.expires_at:
                del self._cache[key]
                self._misses += 1
                return None
            # Update last accessed time for LRU
            entry.last_accessed = datetime.now()
            self._hits += 1
            return entry.value

    def set(self, key: str, value: Any, ttl_seconds: int | None = None) -> None:
        """Set value with optional custom TTL."""
        ttl = timedelta(seconds=ttl_seconds) if ttl_seconds else self._default_ttl
        now = datetime.now()
        expires_at = now + ttl

        with self._lock:
            # Evict if at max size and key is new
            if self._max_size > 0 and key not in self._cache:
                self._evict_if_needed()

            self._cache[key] = CacheEntry(
                value=value,
                expires_at=expires_at,
                last_accessed=now,
            )

    def _evict_if_needed(self) -> None:
        """Evict entries if cache is at max size. Called with lock held."""
        if self._max_size <= 0:
            return

        # First, remove expired entries
        now = datetime.now()
        expired_keys = [k for k, v in self._cache.items() if now > v.expires_at]
        for key in expired_keys:
            del self._cache[key]

        # If still at/over max, evict least recently used
        while len(self._cache) >= self._max_size:
            if not self._cache:
                break
            # Find LRU entry
            lru_key = min(self._cache.keys(), key=lambda k: self._cache[k].last_accessed)
            del self._cache[lru_key]

    def delete(self, key: str) -> None:
        """Delete a key from cache."""
        with self._lock:
            self._cache.pop(key, None)

    def clear(self) -> None:
        """Clear all cached values."""
        with self._lock:
            self._cache.clear()
            self._hits = 0
            self._misses = 0

    def cleanup_expired(self) -> int:
        """Remove all expired entries. Returns count removed."""
        now = datetime.now()
        removed = 0
        with self._lock:
            expired_keys = [k for k, v in self._cache.items() if now > v.expires_at]
            for key in expired_keys:
                del self._cache[key]
                removed += 1
        return removed

    @property
    def size(self) -> int:
        """Current number of entries (including possibly expired)."""
        return len(self._cache)

    @property
    def max_size(self) -> int:
        """Maximum cache size (0 = unlimited)."""
        return self._max_size

    def stats(self) -> dict:
        """Get cache statistics."""
        now = datetime.now()
        with self._lock:
            total = len(self._cache)
            expired = sum(1 for v in self._cache.values() if now > v.expires_at)
            total_requests = self._hits + self._misses
            hit_rate = self._hits / total_requests if total_requests > 0 else 0
            return {
                "total_entries": total,
                "active_entries": total - expired,
                "expired_entries": expired,
                "max_size": self._max_size,
                "hits": self._hits,
                "misses": self._misses,
                "hit_rate": round(hit_rate, 3),
            }


# Module-level lock for PersistentTTLCache SQLite access
# All instances share this lock to prevent "database is locked" errors
# when multiple SportsDataService instances exist (each with their own cache)
_persistent_cache_lock = threading.Lock()


class PersistentTTLCache:
    """SQLite-backed cache with TTL support.

    Same interface as TTLCache but persists to SQLite.
    Survives application restarts while respecting TTL expiration.

    Note: Uses a module-level lock (not instance lock) because multiple
    cache instances may exist but all share the same SQLite database.

    Usage:
        cache = PersistentTTLCache(default_ttl_seconds=3600)
        cache.set("key", value)
        result = cache.get("key")  # Returns None if expired
    """

    def __init__(self, default_ttl_seconds: int = 3600):
        self._default_ttl = timedelta(seconds=default_ttl_seconds)
        self._hits = 0
        self._misses = 0

    def get(self, key: str) -> Any | None:
        """Get value if exists and not expired."""
        from teamarr.database.connection import get_db

        with _persistent_cache_lock:
            now = datetime.now()
            with get_db() as conn:
                row = conn.execute(
                    """
                    SELECT data_json, expires_at FROM service_cache
                    WHERE cache_key = ?
                    """,
                    (key,),
                ).fetchone()

            if row is None:
                self._misses += 1
                return None

            expires_at = datetime.fromisoformat(row["expires_at"])
            if now > expires_at:
                # Expired - delete and return None
                self._delete_key(key)
                self._misses += 1
                return None

            self._hits += 1
            try:
                return json.loads(row["data_json"])
            except json.JSONDecodeError:
                logger.warning(f"Failed to decode cached value for key: {key}")
                self._delete_key(key)
                return None

    def set(self, key: str, value: Any, ttl_seconds: int | None = None) -> None:
        """Set value with optional custom TTL."""
        from teamarr.database.connection import get_db

        ttl = timedelta(seconds=ttl_seconds) if ttl_seconds else self._default_ttl
        now = datetime.now()
        expires_at = now + ttl

        try:
            data_json = json.dumps(value, default=str)
        except (TypeError, ValueError) as e:
            logger.warning(f"Failed to serialize value for key {key}: {e}")
            return

        with _persistent_cache_lock:
            with get_db() as conn:
                conn.execute(
                    """
                    INSERT OR REPLACE INTO service_cache
                    (cache_key, data_json, expires_at, created_at)
                    VALUES (?, ?, ?, ?)
                    """,
                    (key, data_json, expires_at.isoformat(), now.isoformat()),
                )

    def _delete_key(self, key: str) -> None:
        """Delete a key (internal, no lock)."""
        from teamarr.database.connection import get_db

        with get_db() as conn:
            conn.execute("DELETE FROM service_cache WHERE cache_key = ?", (key,))

    def delete(self, key: str) -> None:
        """Delete a key from cache."""
        with _persistent_cache_lock:
            self._delete_key(key)

    def clear(self) -> None:
        """Clear all cached values."""
        from teamarr.database.connection import get_db

        with _persistent_cache_lock:
            with get_db() as conn:
                conn.execute("DELETE FROM service_cache")
            self._hits = 0
            self._misses = 0

    def cleanup_expired(self) -> int:
        """Remove all expired entries. Returns count removed."""
        from teamarr.database.connection import get_db

        now = datetime.now().isoformat()
        with _persistent_cache_lock:
            with get_db() as conn:
                cursor = conn.execute(
                    "DELETE FROM service_cache WHERE expires_at < ?", (now,)
                )
                return cursor.rowcount

    @property
    def size(self) -> int:
        """Current number of entries (including possibly expired)."""
        from teamarr.database.connection import get_db

        with get_db() as conn:
            row = conn.execute("SELECT COUNT(*) as cnt FROM service_cache").fetchone()
            return row["cnt"] if row else 0

    def stats(self) -> dict:
        """Get cache statistics."""
        from teamarr.database.connection import get_db

        now = datetime.now().isoformat()
        with _persistent_cache_lock:
            with get_db() as conn:
                total_row = conn.execute(
                    "SELECT COUNT(*) as cnt FROM service_cache"
                ).fetchone()
                expired_row = conn.execute(
                    "SELECT COUNT(*) as cnt FROM service_cache WHERE expires_at < ?",
                    (now,),
                ).fetchone()

            total = total_row["cnt"] if total_row else 0
            expired = expired_row["cnt"] if expired_row else 0
            total_requests = self._hits + self._misses
            hit_rate = self._hits / total_requests if total_requests > 0 else 0

            return {
                "total_entries": total,
                "active_entries": total - expired,
                "expired_entries": expired,
                "hits": self._hits,
                "misses": self._misses,
                "hit_rate": round(hit_rate, 3),
                "persistent": True,
            }


# Cache TTL constants (seconds)
# Optimized for typical EPG regeneration patterns (hourly to 24hr)
CACHE_TTL_TEAM_STATS = 4 * 60 * 60  # 4 hours - record/standings change infrequently
CACHE_TTL_SCHEDULE = 8 * 60 * 60  # 8 hours - team schedules rarely change
CACHE_TTL_EVENTS = 8 * 60 * 60  # 8 hours - scoreboard (league events list)
CACHE_TTL_SINGLE_EVENT = 30 * 60  # 30 minutes - individual event (scores, odds)
CACHE_TTL_TEAM_INFO = 24 * 60 * 60  # 24 hours - static team data


def make_cache_key(*parts: str) -> str:
    """Create a cache key from parts."""
    return ":".join(str(p) for p in parts)


def get_events_cache_ttl(target_date) -> int:
    """Get cache TTL for events based on date proximity.

    Tiered caching - past events are final (long TTL), today needs fresh data.

    Past:       180 days (final scores don't change)
    Today:      30 minutes (flex times, live scores)
    Tomorrow:   4 hours (flex scheduling possible)
    Days 2-7:   8 hours (mostly stable)
    Days 8+:    8 hours (playoffs may appear)
    """
    from datetime import date

    today = date.today()
    days_from_today = (target_date - today).days

    if days_from_today < 0:  # Past
        return 180 * 24 * 60 * 60  # 180 days
    elif days_from_today == 0:  # Today
        return 30 * 60  # 30 minutes
    elif days_from_today == 1:  # Tomorrow
        return 4 * 60 * 60  # 4 hours
    else:  # Days 2+
        return 8 * 60 * 60  # 8 hours
